# -*- coding: utf-8 -*-
"""PubMed_Abstract_Categorization.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lvAiNl_jFGARIFnLJ6c0iUxaqgtDlBwX

<h1><center><font size=7>PubMed Abstract Categorization and Tagging</center></font></h1>

## Installing and Importing Necessary Libraries and Dependencies
"""

# Installation for GPU llama-cpp-python
!CMAKE_ARGS="-DLLAMA_CUBLAS=on" FORCE_CMAKE=1 pip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir -q

# For downloading the models from HF Hub
!pip install huggingface_hub -q

# Importing library for data manipulation
import pandas as pd

# Function to download the model from the Hugging Face model hub
from huggingface_hub import hf_hub_download

# Importing the Llama class from the llama_cpp module
from llama_cpp import Llama

# Importing the json module
import json

"""## Loading the Data"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
data = pd.read_excel("/content/drive/MyDrive/Previous_Projects/PubMed.xlsx")

"""## Data Overview

### Checking the first 5 rows of the data
"""

data.head()



"""### Checking the shape of the data"""

data.shape

"""* There are 20 rows and 5 columns

### Checking the missing values in the data
"""

data.isnull().sum()

"""* There are no missing values in the data

## Model Building

### Loading the model
"""

model_name_or_path = "TheBloke/Llama-2-13B-chat-GGUF"
model_basename = "llama-2-13b-chat.Q5_K_M.gguf" # the model is in gguf format

model_path = hf_hub_download(
    repo_id=model_name_or_path,
    filename=model_basename
)

lcpp_llm = Llama(
    model_path=model_path,
    n_threads=2,  # CPU cores
    n_batch=512,  # Should be between 1 and n_ctx, consider the amount of VRAM in your GPU.
    n_gpu_layers=43,  # Change this value based on your model and your GPU VRAM pool.
    n_ctx=4096,  # Context window
)

"""### Defining Model Response Parameters"""

def generate_llama_response(instruction, review):

    # System message explicitly instructing not to include the review text
    system_message = """
        [INST]<<SYS>>
        {}
        <</SYS>>[/INST]
    """.format(instruction)

    # Combine user_prompt and system_message to create the prompt
    prompt = f"{review}\n{system_message}"

    # Generate a response from the LLaMA model
    response = lcpp_llm(
        prompt=prompt,
        max_tokens=1024,
        temperature=0,
        top_p=0.95,
        repeat_penalty=1.1,
        top_k=50,
        stop=['INST'],
        echo=False,
        seed=42,
    )

    # Extract the sentiment from the response
    response_text = response["choices"][0]["text"]
    return response_text

df = data.sample(frac = 1)

"""## Task 1: Article Categorization"""

# creating a copy of the data
df1 = df.copy()

# defining the instructions for the model
instruction_A = """
    You are an AI expert. Classify the abstracts based on the Abstract Text presented
    in the input into the following categories
      - Cancer Article
      - Covid Article
      - Diabetes Article
"""

df1['llama_response'] = df1['abstract'].apply(lambda x: generate_llama_response(instruction_A, x))

df1['llama_response'].head()

i = 1
print(df1.loc[i, 'abstract'])

print(df1.loc[i, 'llama_response'])

def extract_category(llama_response):
    if 'cancer article' in llama_response.lower():
        return 'Cancer article'
    elif 'diabetes article' in llama_response.lower():
        return 'Diabetes article'
    elif 'covid article' in llama_response.lower():
        return 'Covid article'

# applying the function to the model response
df1['Category'] = df1['llama_response'].apply(extract_category)
df1['Category'].head()

df1['Category'].value_counts()

final_df1 = df1.drop(['llama_response'], axis=1)
final_df1.head()

"""## Task 2: Abstract Categorization and Returning Structured Output"""

# creating a copy of the data
df2 = data.copy()

# defining the instructions for the model
instruction_B = """
   You are an AI expert. Classify the abstracts based on the Abstract Text presented
    in the input into the following categories
      - Cancer Article
      - Covid Article
      - Diabetes Article

    Format the output as a JSON object with a single key-value pair as shown below:
    {"Category": "your_category_prediction"}
"""

df2['llama_response'] = df2['abstract'].apply(lambda x: generate_llama_response(instruction_B, x))

df2['llama_response'].head()

i = 2
print(df2.loc[i, 'abstract'])

print(df2.loc[i, 'llama_response'])

# defining a function to parse the JSON output from the model
def json_extractor(json_str):
    try:
        # Find the indices of the opening and closing curly braces
        json_start = json_str.find('{')
        json_end = json_str.rfind('}')

        if json_start != -1 and json_end != -1:
            extracted_category = json_str[json_start:json_end + 1]  # Extract the JSON object
            dfdict = json.loads(extracted_category)
            return dfdict
        else:
            print(f"Warning: JSON object not found in response: {json_str}")
            return {}
    except json.JSONDecodeError as e:
        print(f"Error parsing JSON: {e}")
        return {}

# Applying the function to the model response
df2['llama_response_parsed'] = df2['llama_response'].apply(json_extractor)
df2['llama_response_parsed'].head()

# Normalizing the llama_response_parsed column
llama_response_parsed_df_2 = pd.json_normalize(df2['llama_response_parsed'])
llama_response_parsed_df_2.head()

# Concatinating two dataframes
dfwith_parsed_model_output_2 = pd.concat([df2, llama_response_parsed_df_2], axis=1)
dfwith_parsed_model_output_2.head()

# Dropping llama_response and llama_response_parsed columns
final_df2 = dfwith_parsed_model_output_2.drop(['llama_response','llama_response_parsed'], axis=1)
final_df2.head()

# Checking the value counts of Category column
final_df2['Category'].value_counts()

"""* `The Utility of Exosomes...` article has not be assigned a category

## Task 3: Abstract Categorization, Creating Tags, and Returning Structured Output
"""

# creating a copy of the data
df3 = df.copy()

# defining the instructions for the model
instruction_C = """
 You are an AI expert. Classify the abstracts based on the Abstract Text presented
    in the input into the following categories
      - Cancer Article
      - Covid Article
      - Diabetes Article

    Once you have identified the Category, then :
        1) Create Tags - This will help us classify the ticket and don't include the category

        Output the category and tags for each category in a JSON format with the following keys:
    {
        "Category": "categories",
        "Tags": "Tag"
    }
"""

# Applying generate_llama_response function on abstract column
df3['llama_response'] = df3['abstract'].apply(lambda x: generate_llama_response(instruction_C, x))

df3['llama_response'].head()

i = 4
print(df3.loc[i, 'abstract'])

print(df3.loc[i, 'llama_response'])

# Applying the function to the model response
df3['llama_response_parsed'] = df3['llama_response'].apply(json_extractor)
df3['llama_response_parsed'].head()

# Normalizing the llama_response_parsed column
llama_response_parsed_df_3 = pd.json_normalize(df3['llama_response_parsed'])
llama_response_parsed_df_3.head(5)

# Concatinating two dataframes
dfwith_parsed_model_output_3 = pd.concat([df3, llama_response_parsed_df_3], axis=1)
dfwith_parsed_model_output_3.head()

# Dropping llama_response and llama_response_parsed columns
final_df3 = dfwith_parsed_model_output_3.drop(['llama_response','llama_response_parsed'], axis=1)
final_df3.head()